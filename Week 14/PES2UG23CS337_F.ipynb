{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":309628,"datasetId":107582,"databundleVersionId":322619,"isSourceIdPinned":false}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Week 14: CNN Lab - Rock, Paper, Scissors\n\n**Objective:** Build, train, and test a Convolutional Neural Network (CNN) to classify images of hands playing Rock, Paper, or Scissors.","metadata":{"id":"intro_cell"}},{"cell_type":"markdown","source":"### Step 1: Setup and Data Download\n\nThis first cell downloads the dataset from Kaggle.","metadata":{"id":"step_1_md"}},{"cell_type":"code","source":"import kagglehub\n\npath = kagglehub.dataset_download(\"drgfreeman/rockpaperscissors\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"id":"DHpeGiatx8yO","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:41.831489Z","iopub.execute_input":"2025-11-20T15:13:41.831906Z","iopub.status.idle":"2025-11-20T15:13:42.095486Z","shell.execute_reply.started":"2025-11-20T15:13:41.831868Z","shell.execute_reply":"2025-11-20T15:13:42.094298Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/rockpaperscissors\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import shutil\nimport os\n\nsrc_root = \"/kaggle/input/rockpaperscissors\"\ndst_root = \"/content/dataset\"\n\nos.makedirs(dst_root, exist_ok=True)\n\nfolders_to_copy = [\"rock\", \"paper\", \"scissors\"]\n\nfor folder in folders_to_copy:\n    src_path = os.path.join(src_root, folder)\n    dst_path = os.path.join(dst_root, folder)\n\n    if os.path.exists(src_path):\n        shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n        print(\"Copied:\", folder)\n    else:\n        print(\"Folder not found:\", folder)\n\n","metadata":{"id":"3SVJhchl2XCb","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:42.097230Z","iopub.execute_input":"2025-11-20T15:13:42.097776Z","iopub.status.idle":"2025-11-20T15:13:55.029841Z","shell.execute_reply.started":"2025-11-20T15:13:42.097739Z","shell.execute_reply":"2025-11-20T15:13:55.028752Z"}},"outputs":[{"name":"stdout","text":"Copied: rock\nCopied: paper\nCopied: scissors\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Step 2: Imports and Device Setup\n\nImport the necessary libraries and check if a GPU is available.","metadata":{"id":"step_2_md"}},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nfrom PIL import Image\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)","metadata":{"id":"1n2gYN8TyydM","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:55.030668Z","iopub.execute_input":"2025-11-20T15:13:55.030951Z","iopub.status.idle":"2025-11-20T15:13:55.041575Z","shell.execute_reply.started":"2025-11-20T15:13:55.030929Z","shell.execute_reply":"2025-11-20T15:13:55.040288Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"### Step 3: Data Loading and Preprocessing\n\nHere we will define our image transformations, load the dataset, split it, and create DataLoaders.","metadata":{"id":"step_3_md"}},{"cell_type":"code","source":"DATA_DIR = \"/content/dataset\"\n\ntransform = transforms.Compose([\n    transforms.Resize((128,128)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\nfull_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\nclass_names = full_dataset.classes\nprint(\"Classes:\", class_names)\n\n# 80/20 split\ntrain_size = int(0.8 * len(full_dataset))\ntest_size = len(full_dataset) - train_size\n\ntrain_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint(f\"Total images: {len(full_dataset)}\")\nprint(f\"Training images: {len(train_dataset)}\")\nprint(f\"Test images: {len(test_dataset)}\")","metadata":{"id":"SkJ5XlSDy0HF","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:55.043889Z","iopub.execute_input":"2025-11-20T15:13:55.044593Z","iopub.status.idle":"2025-11-20T15:13:55.161126Z","shell.execute_reply.started":"2025-11-20T15:13:55.044558Z","shell.execute_reply":"2025-11-20T15:13:55.159979Z"}},"outputs":[{"name":"stdout","text":"Classes: ['paper', 'rock', 'scissors']\nTotal images: 2188\nTraining images: 1750\nTest images: 438\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"### Step 4: Define the CNN Model\n\nFill in the `conv_block` and `fc_block` with the correct layers.","metadata":{"id":"step_4_md"}},{"cell_type":"code","source":"class RPS_CNN(nn.Module):\n    def __init__(self):\n        super(RPS_CNN, self).__init__()\n\n        self.conv_block = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n        )\n\n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 16 * 16, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 3)\n        )\n\n    def forward(self, x):\n        x = self.conv_block(x)\n        x = self.fc(x)\n        return x\n\nmodel = RPS_CNN().to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nprint(model)","metadata":{"id":"wexPK8V3y3Fx","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:55.162495Z","iopub.execute_input":"2025-11-20T15:13:55.162824Z","iopub.status.idle":"2025-11-20T15:13:55.234100Z","shell.execute_reply.started":"2025-11-20T15:13:55.162797Z","shell.execute_reply":"2025-11-20T15:13:55.232916Z"}},"outputs":[{"name":"stdout","text":"RPS_CNN(\n  (conv_block): Sequential(\n    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (4): ReLU()\n    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU()\n    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (fc): Sequential(\n    (0): Flatten(start_dim=1, end_dim=-1)\n    (1): Linear(in_features=16384, out_features=256, bias=True)\n    (2): ReLU()\n    (3): Dropout(p=0.3, inplace=False)\n    (4): Linear(in_features=256, out_features=3, bias=True)\n  )\n)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"### Step 5: Train the Model\n\nFill in the core training steps inside the loop.","metadata":{"id":"step_5_md"}},{"cell_type":"code","source":"EPOCHS = 10\n\nfor epoch in range(EPOCHS):\n    model.train()\n    total_loss = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss = {total_loss/len(train_loader):.4f}\")\n\nprint(\"Training complete!\")","metadata":{"id":"L_GqO57IzQLs","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:13:55.235622Z","iopub.execute_input":"2025-11-20T15:13:55.235962Z","iopub.status.idle":"2025-11-20T15:16:57.917283Z","shell.execute_reply.started":"2025-11-20T15:13:55.235938Z","shell.execute_reply":"2025-11-20T15:16:57.916349Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss = 0.6032\nEpoch 2/10, Loss = 0.1674\nEpoch 3/10, Loss = 0.0899\nEpoch 4/10, Loss = 0.0604\nEpoch 5/10, Loss = 0.0281\nEpoch 6/10, Loss = 0.0218\nEpoch 7/10, Loss = 0.0264\nEpoch 8/10, Loss = 0.0054\nEpoch 9/10, Loss = 0.0124\nEpoch 10/10, Loss = 0.0121\nTraining complete!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### Step 6: Evaluate the Model\n\nTest the model's accuracy on the unseen test set.","metadata":{"id":"step_6_md"}},{"cell_type":"code","source":"model.eval()\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint(f\"Test Accuracy: {100 * correct / total:.2f}%\")","metadata":{"id":"iYCNxBrjzU1t","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:16:57.918260Z","iopub.execute_input":"2025-11-20T15:16:57.918479Z","iopub.status.idle":"2025-11-20T15:17:00.410966Z","shell.execute_reply.started":"2025-11-20T15:16:57.918464Z","shell.execute_reply":"2025-11-20T15:17:00.410163Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 98.63%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"### Step 7: Test on a Single Image\n\nLet's see how the model performs on one image.","metadata":{"id":"step_7_md"}},{"cell_type":"code","source":"def predict_image(model, img_path):\n    model.eval()\n\n    img = Image.open(img_path).convert(\"RGB\")\n    img = transform(img).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        output = model(img)\n        _, pred = torch.max(output, 1)\n\n    return class_names[pred.item()]\n\ntest_img_path = \"/content/dataset/paper/0Uomd0HvOB33m47I.png\"\nprediction = predict_image(model, test_img_path)\nprint(f\"Model prediction for {test_img_path}: {prediction}\")","metadata":{"id":"RN00Dkw9zceh","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:17:00.411670Z","iopub.execute_input":"2025-11-20T15:17:00.411925Z","iopub.status.idle":"2025-11-20T15:17:00.434193Z","shell.execute_reply.started":"2025-11-20T15:17:00.411907Z","shell.execute_reply":"2025-11-20T15:17:00.432519Z"}},"outputs":[{"name":"stdout","text":"Model prediction for /content/dataset/paper/0Uomd0HvOB33m47I.png: paper\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"### Step 8: Play the Game!\n\nThis code is complete. If your model is trained, you can run this cell to have the model play against itself.","metadata":{"id":"step_8_md"}},{"cell_type":"code","source":"import random\nimport os\n\ndef pick_random_image(class_name):\n    folder = f\"/content/dataset/{class_name}\"\n    files = os.listdir(folder)\n    img = random.choice(files)\n    return os.path.join(folder, img)\n\ndef rps_winner(move1, move2):\n    if move1 == move2:\n        return \"Draw\"\n\n    rules = {\n        \"rock\": \"scissors\",\n        \"paper\": \"rock\",\n        \"scissors\": \"paper\"\n    }\n\n    if rules[move1] == move2:\n        return f\"Player 1 wins! {move1} beats {move2}\"\n    else:\n        return f\"Player 2 wins! {move2} beats {move1}\"\n\n\n# -----------------------------------------------------------\n# 1. Choose any two random classes\n# -----------------------------------------------------------\n\nchoices = [\"rock\", \"paper\", \"scissors\"]\nc1 = random.choice(choices)\nc2 = random.choice(choices)\n\nimg1_path = pick_random_image(c1)\nimg2_path = pick_random_image(c2)\n\nprint(\"Randomly selected images:\")\nprint(\"Image 1:\", img1_path)\nprint(\"Image 2:\", img2_path)\n\n\n# -----------------------------------------------------------\n# 2. Predict their labels using the model\n# -----------------------------------------------------------\n\np1 = predict_image(model, img1_path)\np2 = predict_image(model, img2_path)\n\nprint(\"\\nPlayer 1 shows:\", p1)\nprint(\"Player 2 shows:\", p2)\n\n# -----------------------------------------------------------\n# 3. Decide the winner\n# -----------------------------------------------------------\n\nprint(\"\\nRESULT:\", rps_winner(p1, p2))","metadata":{"id":"13-RXEbuzuxu","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T15:17:00.436075Z","iopub.execute_input":"2025-11-20T15:17:00.437432Z","iopub.status.idle":"2025-11-20T15:17:00.478156Z","shell.execute_reply.started":"2025-11-20T15:17:00.437400Z","shell.execute_reply":"2025-11-20T15:17:00.476480Z"}},"outputs":[{"name":"stdout","text":"Randomly selected images:\nImage 1: /content/dataset/paper/kz9TBAHLFXGnHCiF.png\nImage 2: /content/dataset/scissors/CO4Xhg1dx5dmvwlo.png\n\nPlayer 1 shows: paper\nPlayer 2 shows: scissors\n\nRESULT: Player 2 wins! scissors beats paper\n","output_type":"stream"}],"execution_count":16}]}
